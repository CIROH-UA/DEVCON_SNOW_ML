{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f45d1d3-2ce5-487c-8d89-a2e0ec3870ec",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "<img align = 'center' src=\"./Images/ML_SWE.jpg\" alt = 'image' width = '1000'/>\n",
    "\n",
    "\n",
    "# Add AORC Precipitation to Training Datasets\n",
    "\n",
    "- Tony Castronova <acastronova@cuahsi.org>\n",
    "- Irene Garousi-Nejad <igarousi@cuahsi.org>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44e9376-f3b9-4b11-a32f-d9af15fde2bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install dask[distributed] zarr xarray pandas s3fs kerchunk scikit-learn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c353a2-226b-4dfb-8db4-c2fbcadb2bf4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import dask\n",
    "import zarr\n",
    "import numpy\n",
    "import xarray\n",
    "import pyproj\n",
    "import pandas\n",
    "from s3fs import S3FileSystem\n",
    "from dask.distributed import Client, progress\n",
    "from kerchunk.combine import MultiZarrToZarr\n",
    "from sklearn.metrics import pairwise_distances_argmin\n",
    "\n",
    "import dask.bag as db  \n",
    "\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "import aorc1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79279a53-22ae-40cc-a05c-67188f18ccc4",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Initiate the Dask client. This will enable us to parallelize our computations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005eb820-57c2-4ad6-81e8-26ed37d4f075",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# use a try accept loop so we only instantiate the client\n",
    "# if it doesn't already exist.\n",
    "try:\n",
    "    print(client.dashboard_link)\n",
    "except:    \n",
    "    # The client should be customized to your workstation resources.\n",
    "    client = Client(n_workers=20)\n",
    "    print(client.dashboard_link)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d4cfb0-c8e4-4843-85f8-294cad5d22df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def extract_dask(search_points, all_points, final_shape):\n",
    "    index = pairwise_distances_argmin(X=search_points,\n",
    "                                      Y=all_points)\n",
    "    i0, j0 = numpy.unravel_index(index, (final_shape))\n",
    "    return(j0, i0)\n",
    "\n",
    "\n",
    "@dask.delayed\n",
    "def get_data_dask(i_locs, j_locs, year='2010', month='01', day='01'):\n",
    "    ds = aorc1.load_aorc_dataset(year, month, day)\n",
    "    precip = ds.isel(x=i_locs, y=j_locs).squeeze().RAINRATE\n",
    "    \n",
    "    \n",
    "    with open(f'{year}{month}{day}.pkl', 'wb') as f:\n",
    "        pickle.dump(precip.values, f)\n",
    "    \n",
    "    return datetime(int(year), int(month), int(day)),\n",
    "\n",
    "\n",
    "def get_data_daskbag(args):\n",
    "    i_locs = args[0]\n",
    "    j_locs = args[1]\n",
    "    dt = args[2]\n",
    "    path = args[3]\n",
    "    \n",
    "    # get the date parts\n",
    "    month = f'{dt.month:02}'    \n",
    "    day = f'{dt.day:02}'\n",
    "    year = f'{dt.year:04}'\n",
    "    \n",
    "    # if os.path.exists(f'{path}/{year}{month}{day}.csv'):\n",
    "    #     return f'{path}/{year}{month}{day}.csv'\n",
    "\n",
    "    ds = aorc1.load_aorc_dataset(year, month, day)\n",
    "    \n",
    "    precip = ds.isel(x=i_locs, y=j_locs) #.squeeze().RAINRATE\n",
    "    precip = precip.RAINRATE.groupby('time.dayofyear').sum() * 24 * 3600\n",
    "    pcp_df = precip.to_dataframe().reset_index()\n",
    "    \n",
    "    pcp_df['date'] = dt\n",
    "    pcp_df = pcp_df[['lat', 'lon', 'RAINRATE', 'date']]\n",
    "    pcp_df.lat = round(pcp_df.lat, 6)  # rounding so they match later \n",
    "    pcp_df.lon = round(pcp_df.lon, 6)  # rounding so they match later\n",
    "    pcp_df.rename(columns={'RAINRATE': 'RAINRATE [mm]'}, inplace=True)\n",
    "    pcp_df.set_index('date', inplace=True)\n",
    "    pcp_df.to_csv(f'{path}/{year}{month}{day}.csv')\n",
    "    \n",
    "    return f'{path}/{year}{month}{day}.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292bb9cd-cf11-4089-accb-fd50b1a99230",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Load AORC V1.0 from AWS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4331f6ce-d72e-4710-9095-208157c260e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# get all of the lat/lon locations in AORC\n",
    "\n",
    "ds = aorc1.load_aorc_dataset('2010', '01', '01')\n",
    "all_pts = numpy.c_[ds['lon'].values.ravel(), ds['lat'].values.ravel()]\n",
    "all_lats = ds['lat'].values\n",
    "all_lons = ds['lon'].values\n",
    "final_shape = ds['lon'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbbfa9d-c62f-42cf-929f-dddfed2ee34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_path = \"/home/jovyan/Snow-Extrapolation/data/RegionTrain_SCA.pkl\"\n",
    "with open(training_path, 'rb') as f:\n",
    "    region_train = pickle.load(f)\n",
    "\n",
    "pts = []\n",
    "locs = []\n",
    "#key = 'N_Sierras'\n",
    "for key in region_train.keys():\n",
    "    region_train[key]['pt'] = list(zip(region_train[key].Long, region_train[key].Lat))\n",
    "    locs.extend([*region_train[key].pt.unique()])\n",
    "\n",
    "print(f'Number of training points = {len(locs)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474acbde-38e8-4515-87fa-b004b6c6c8c5",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Collect Precip for Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332272da-e2bb-418c-924b-372a98776a2a",
   "metadata": {
    "tags": [],
    "user_expressions": []
   },
   "source": [
    "Find aorc lats/lons that intersect with aorc points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ce1634-61d9-48b3-8fa7-4d882f808ef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# batch index collection using dask\n",
    "number_of_groups = 10\n",
    "pt_groups = numpy.array_split(numpy.array(locs), number_of_groups)\n",
    "\n",
    "print('scattering...', end='', flush=True)\n",
    "all_pts_scattered = client.scatter(all_pts)\n",
    "print('done')\n",
    "\n",
    "futures = []\n",
    "for grp in pt_groups:\n",
    "    futures.append(extract_dask(grp, all_pts_scattered, final_shape)) \n",
    "\n",
    "print('finding aorc lats/lons...', end='', flush=True)\n",
    "results = dask.compute(futures)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86898494-ab46-42bb-953c-f9756da80d5e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# put the x,y coordinates for the matching cells into lists\n",
    "i_locs = []\n",
    "j_locs = []\n",
    "for grp in results[0]:\n",
    "    num_elements = len(grp[0])\n",
    "    for idx in range(0, num_elements):\n",
    "        i_locs.append(grp[0][idx])\n",
    "        j_locs.append(grp[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5856fb83-1da8-4379-b0df-f789ab2793c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create mapping between nsm lat/lon and aorc i,j \n",
    "data = []\n",
    "for i in range(0, len(i_locs)):\n",
    "    aorc_lat = round(all_lats[j_locs[i]][i_locs[i]], 6)\n",
    "    aorc_lon = round(all_lons[j_locs[i]][i_locs[i]], 6)\n",
    "    data.append([locs[i][0], locs[i][1], i_locs[i], j_locs[i], aorc_lon, aorc_lat])\n",
    "\n",
    "headers = ['nsm_long', 'nsm_lat', 'aorc_i', 'aorc_j', 'aorc_lon', 'aorc_lat'] \n",
    "\n",
    "loc_map = pandas.DataFrame(columns=headers, data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d2de2b-2219-41bd-a398-0ee32097783a",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "Download the data from the cloud and save to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999b726c-1934-495d-aa5e-dd2583491371",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "if not os.path.exists('data'):\n",
    "    os.mkdir('data')\n",
    "    \n",
    "    \n",
    "# batch variable collection\n",
    "t = datetime(2012,12,21)\n",
    "et = datetime(2020,1,10)\n",
    "\n",
    "# create dataarrays for subsetting aorc pointwise\n",
    "ind_x = xarray.DataArray(i_locs, dims=[\"pt\"])\n",
    "ind_y = xarray.DataArray(j_locs, dims=[\"pt\"])\n",
    "\n",
    "input_params = []\n",
    "while t <= et:\n",
    "    if not os.path.exists(f\"data/{t.strftime('%Y%m%d')}.csv\"):\n",
    "        input_params.append([ind_x, ind_y, t, 'data'])\n",
    "    t += timedelta(days=1)\n",
    "    \n",
    "b = db.from_sequence(input_params, npartitions=25)\n",
    "b = b.map(get_data_daskbag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72d9f28-dfbe-470e-ae8e-b95b965947f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "results = b.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e568599d-1fb6-4c8d-836e-5854f720132d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we don't need dask anymore, so release all memory consumed by it\n",
    "client.cluster.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc1e7ff6-3cba-4551-b08d-3ebf45c61cb6",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "## Load Precip from Disk and Summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8bf749a-358b-445e-8f97-6084dc67d5a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load aorc precip from CSVs into a dataframe\n",
    "#df_precip = pandas.concat([pandas.read_csv(f) for f in results])\n",
    "\n",
    "df_precip = pandas.concat([pandas.read_csv(f) for f in glob('data/*.csv')])\n",
    "\n",
    "df_precip.date = pandas.to_datetime(df_precip.date)\n",
    "df_precip.set_index('date', inplace=True)\n",
    "\n",
    "# compute weekly precip\n",
    "df_precip = df_precip.groupby(['lat', 'lon', pandas.Grouper(freq='W-Tue')]).sum().reset_index()\n",
    "\n",
    "# rename columns\n",
    "df_precip.rename(columns={'RAINRATE [mm]':'aorc-precip-weekly-mm', 'lat':'aorc_lat', 'lon':'aorc_lon'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0dfc72-87c1-4c08-a753-b27234b9449d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# adding aorc lat/lon so we can join into the training dataset\n",
    "df_precip = pandas.merge(df_precip, loc_map, how='left',\n",
    "             left_on=['aorc_lon', 'aorc_lat'],\n",
    "             right_on=['aorc_lon', 'aorc_lat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c1850-626f-4f47-93f3-0d1cf0ee99fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# compute shifted precip\n",
    "for idx, _ in df_precip.groupby(['nsm_long', 'nsm_lat']):\n",
    "    d = df_precip.loc[(df_precip.nsm_long == idx[0]) & (df_precip.nsm_lat == idx[1])]['aorc-precip-weekly-mm'].shift(1)\n",
    "    df_precip.loc[(df_precip.nsm_long == idx[0]) & (df_precip.nsm_lat == idx[1]), 'Prev_aorc-precip-weekly-mm'] = d \n",
    "\n",
    "## TODO reset accumulation at the beginning of every year\n",
    "# # compute cumulative precip \n",
    "# for idx, _ in df_precip.groupby(['nsm_long', 'nsm_lat']):\n",
    "#     d = df_precip.loc[(df_precip.nsm_long == idx[0]) & (df_precip.nsm_lat == idx[1])]['aorc-precip-weekly-mm'].cumsum()\n",
    "#     df_precip.loc[(df_precip.nsm_long == idx[0]) & (df_precip.nsm_lat == idx[1]), 'cum-precip-mm'] = d \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4d7cf6-6c98-4722-a55b-0472e2f36d02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_precip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5821c26-efa2-408a-b7c3-eb2bd1d7ae73",
   "metadata": {
    "user_expressions": []
   },
   "source": [
    "### Add AORC precip to the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e978ab5-ffa9-4cc1-8cf5-dfcd3f98d6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for key in region_train.keys():\n",
    "    train_df = region_train[key]\n",
    "    train_df.reset_index(inplace=True)\n",
    "    train_df = pandas.merge(train_df, df_precip[['aorc-precip-weekly-mm', 'Prev_aorc-precip-weekly-mm', 'date', 'nsm_long', 'nsm_lat']],\n",
    "                          how='left', left_on=['Date', 'Long', 'Lat'],\n",
    "                          right_on=['date', 'nsm_long', 'nsm_lat']).set_index('index')\n",
    "    # train_df = pandas.merge(train_df, df_precip[['cum-precip-mm', 'date', 'nsm_long', 'nsm_lat']],\n",
    "    #                       how='left', left_on=['Date', 'Long', 'Lat'],\n",
    "    #                       right_on=['date', 'nsm_long', 'nsm_lat']).set_index('index')\n",
    "    train_df.drop(['date', 'nsm_long', 'nsm_lat'], inplace=True, axis=1)\n",
    "    \n",
    "    # save this back to the training dataset\n",
    "    region_train[key] = train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c267e70-aa1e-499f-8cc1-00580970844e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_path = \"RegionTrain_SCA.pkl\"\n",
    "with open(training_path, 'wb') as f:\n",
    "    pickle.dump(region_train, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c946dc3-526b-490f-b7c4-4bc4f59dd3b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
